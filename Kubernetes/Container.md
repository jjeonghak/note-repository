# 쿠버네티스

쿠버네티스는 하드웨어 인프라를 추상화  
데이터 센터 전체를 하나의 거대한 컴퓨팅 리소스로 제공  
애플리케이션을 격리하는 기능을 제공하기 위해 리눅스 컨테이너 기술 사용  

<br>

## 컨테이너 이해
가상 머신을 이용해 마이크로서비스 환경을 격리하는 대신 리눅스 컨테이너 기술을 사용  
동일 호스트 시스템에서 여러 개의 서비스 실행 가능, 가상머신과 유사하게 서로 격리  
컨테이너는 `호스트 os`에서 실행되는 하나의 격리된 프로세스  
가상 머신은 구성 요소 프로세스 뿐만 아니라 시스템 프로세스를 실행하기 때문에 추가 컴퓨팅 리소스 필요  
애플리케이션은 `게스트 os 커널`에 시스템 콜을 호출, 커널은 `하이퍼바이저`로 호스트의 물리적 cpu에 x86 명령 수행  
반면 컨테이너는 모두 동일한 커널을 호출하기 때문에 보안 위험이 발생 가능  

<img width="600" height="500" alt="container_and_vm" src="https://github.com/user-attachments/assets/67462069-63d6-4f1e-9936-006522b3cf97" />

<br>
<br>

## 컨테이너 격리 메커니즘
1. 리눅스 네임스페이스(`namespace`)로 각 프로세스가 시스템에 대한 독립된 뷰만 조회
2. 리눅스 컨트롤 그룹(`cgroups`)을 이용한 사용 가능 리소스 제한

<br>

### 리눅스 네임스페이스로 프로세스 격리
기본적으로 각 리눅스 시스템은 초기 구동 시 하나의 네임스페이스 존재  
프로세스를 실행할 때는 해당 네임스페이스 중 하나에서 프로세스 실행  
네임스페이스 종류는 아래와 같음  
- 마운트(`mnt`)
- 프로세스 ID(`pid`)
- 네트워크(`net`)
- 프로세스 간 통신(`ipc`)
- 호스트와 도메인 이름(`uts`)
- 사용자 ID(`user`)

<br>

### 프로세스의 가용 리소스 제한
프로세스의 리소스 사용을 제한하는 리눅스 커널 기능 `cgroups`로 수행  
설정된 양 이상의 CPU, 메모리, 네트워크 대역폭 등 사용 불가  

<br>

### 컨테이너 이미지의 제한적인 이식성 이해
이론적으로 컨테이너 이미지는 도커를 실행하는 모든 리눅스 시스템에서 실행 가능  
하지만 컨테이너화된 애플리케이션이 특정 커널 버전이 필요하다면 모든 시스템에서 작동하지 않을 가능성 존재  
즉 `x86` 아키텍처용 애플리케이션이 `ARM` 기반 컴퓨터에서 도커가 있더라도 컨테이너 불가능  

<br>

## 쿠버네티스 소개
구글은 보그(`Bog`, 이후 오메가로 변경)라는 내부 시스템을 개발  
2014년에 보그, 오메가, 기타 내부 구글 시스템으로 얻은 경험을 기반으로 오픈소스 쿠버네티스 출시  

<br>

### 쿠버네티스 핵심 이해
시스템은 마스터(`master`) 노드와 워커(`worker`) 노드로 구성  
애플리케이션 `매니페스트`를 마스터에 게시하면 쿠버네티스가 해당 애플리케이션을 워커 노드 클러스터에 배포  

<img width="600" height="400" alt="master_and_worker" src="https://github.com/user-attachments/assets/0298b76a-b072-43f8-833e-e3a9dc54cfd8" />

<br>
<br>

### 쿠버네티스 클러스터 아키텍처 이해
마스터 노드는 전체 쿠버네티스 시스템을 제어하고 관리하는 `컨트롤 플레인`을 실행  
워커 노드는 실제 배포되는 컨테이너 애플리케이션을 실행  

<img width="600" height="300" alt="cluster" src="https://github.com/user-attachments/assets/e17a8ac5-6d55-4f32-ab31-2ea46364bf02" />

<br>
<br>

### 컨트롤 플레인
클러스터를 제어하고 작동시킴  
하나의 마스터 노드에서 실행하거나 여러 노드로 분할 가능  
클러스터 상태를 유지하고 제어하지만 애플리케이션을 직접 실행하지 않음  
- `쿠버네티스 API 서버`: 사용자, 컨트롤 플레인 구성 요소와 통신
- `스케줄러`: 애플리케이션 배포 담당
- `컨트롤러 매니저`: 구성 요소 복제본, 워커 노드 추적, 노드 장애 처리 등 클러스터단의 기능 수행
- `etcd`: 클러스터 구성을 지속적으로 저장하는 분산 데이터 저장소

<br>

### 노드
컨테이너화된 애플리케이션을 실행하는 시스템  
- 컨테이너를 실행하는 `docker`, `rkt` 또는 다른 컨테이너 런타임
- API 서버와 통신하고 노드의 컨테이너를 관리하는 `kubelet`
- 네트워크 트래픽을 로드밸런싱하는 쿠버네티스 서비스 프록시 `kube-proxy`

<br>

### 쿠버네티스에서 애플리케이션 실행
애플리케이션을 하나 이상의 컨테이너 이미지로 패키징  
해당 이미지를 이미지 레지스트리로 추시  
쿠버네티스 API 서버에 애플리케이션 디스크립션을 게시  

<br>

### 디스크립션 이해
스케줄러는 각 컨테이너에 필요한 리소스를 계산하고, 사용 가능한 워커 노드에 지정된 컨테이너 할당  
해당 노드의 kubelet은 컨테이너 런타임에 필요한 컨테이너 이미지를 가져와 실행 지시  

<img width="700" height="600" alt="deploy_flow" src="https://github.com/user-attachments/assets/2c70a4e9-9a3f-42d3-ac1d-4212c50ea7d5" />

<br>
<br>

### 실행된 컨테이너 유지
애플리케이션 실행후 쿠버네티스는 배포 상태가 사용자의 디스크립션과 일치하는지 지속적으로 확인  
만약 워커 노드 중 문제가 발생한 경우 실행 중인 모든 컨테이너의 노드를 새로 스케줄링  

<br>

### 이동한 애플리케이션 접근
쿠버네티스는 하나의 고정 ip 주소로 모든 컨테이너를 노출  
kube-proxy가 서비스를 제공하는 모든 컨테이너에서 서비스 연결이 로드밸런싱되도록 동작  
서비스 ip 주고는 일정하게 유지되므로 컨테이너가 클러스터 내에서 이동하더라도 항상 연결 가능  

<br>
